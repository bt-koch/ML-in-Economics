---
output:
  pdf_document:
    number_sections: true
indent: true
    # template: tex/template.tex
bibliography: tex/bibliography.bib
biblio-style: text/econometrica.bst
header-includes:
  - \usepackage{floatrow}
  - \floatsetup{capposition=top}
  - \usepackage{setspace}
  # - \usepackage{indentfirst}
editor_options: 
  markdown: 
    wrap: 72
---

<!-- Setup -------------------------------------------------------------------->

```{r setup, include=FALSE}
if(!require(kableExtra)) install.packages("kableExtra")
if(!require(randomForest)) install.packages("randomForest")
if(!require(iml)) install.packages("iml")

library(kableExtra)
library(randomForest)
library(iml)

knitr::opts_chunk$set(echo = FALSE, fig.align = "center")

load("data/input.RData")
varnames <- list.export[["varnames"]]
```

<!-- Title Page + TOC --------------------------------------------------------->

```{=tex}
\newpage
\vspace*{4cm}
\begin{center}
{\Large Machine Learning in Economics \\ (458657)}
\end{center}
\vspace*{1.5cm}
\begin{center}
\thispagestyle{empty}
{\LARGE \bf replication paper}\\[1.5cm]
{\Huge Early Warning System for Fiscal Stress}\\[1.5cm]
{\bf \Large comparing the traditional logistic regression approach \\ with random forest}\\[2cm]
{\bf \large Department of Economics\\
University of Bern}\\[1cm]
{\Large Spring Semester 2022}\\[1.5cm]
{\large submitted by Bela Tim Koch} \\[2.5cm]
\end{center}
```
```{=tex}
\newpage
\thispagestyle{empty}
\tableofcontents
\newpage
```
<!-- Report ------------------------------------------------------------------->

```{=html}
<!--  1 Title Page
      2 TOC
      3 Introduction + Literature Review
      4-5.5 Model Description
      5.5-7 Data Description
      8-9 Results
      10 Conclusion
-->
```
```{=tex}
\setcounter{page}{1}
\onehalfspace
```
# Introduction and Literature Review

Since the latest Great Recession with its corresponding deterioration of
public finances, the monitoring and prevention of fiscal crises has
become increasingly prominent in the political debate, leading to an
increasing demand for the development of reliable and early indicators
that signal possible fiscal stress. In order to be able to assess
countries' vulnerability to fiscal distress ex-ante, the literature is
increasingly devoted to the development of early warning systems for
fiscal stress, which build on early warning systems for banking and
currency crises [@honda2022]. The standard tool used in the literature
for early warning systems are the signalling approach as well as
discrete dependent variable models, such as logistic regression
[@jarmulska2020].

As an alternative to the traditional methods, early warning models based
on machine learning techniques are proposed, claiming a possible
improvement of prediction accuracy [@beutel2019]. As an example, when
predicting the build-up of banking crises, the early warning system
developed by @casabianca2019 which builds upon a supervised machine
learning algorithm, i.e. Adaptive Boosting, outperforms the traditional
approach of using a logit model. Another example which shows that using
machine learning could drastically improve prediction accuracy is the
early warning system developed by @samitas2020, which reaches an
accuracy of 98.8% when predicting the risk of contagion inside a
financial network using a quadratic support vector machine.

However, a disadvantage many of these machine learning methods compared
to more traditional approaches is the difficulty of understanding how a
result was obtained and are therefore often referred to as a black box
[@ghoddusi2019]. Consequently, the researcher is confronted with a
trade-off between prediction or interpretation. @ghoddusi2019 argue,
that emphasis should be in interpretation for scientific research or
policy decisions, since understanding the relationship and behavior
among different variables is more important than prediction accuracy. In
contrast, more emphasis is to be placed on prediction accuracy in
specific industrial applications.

This paper aims to replicate some of the work done by @jarmulska2020.
Particular emphasis is placed on the comparison of the traditional
method, i.e. a logit model with a least absolute shrinkage and selection
operator, and a model based on machine learning, i.e. an implementation
of the random forest algorithm. As the results are often criticized for
being difficult to interpret, ways of interpreting the developed early
warning model based on random forest are presented.

*to do: noch ein paar beispielpapers hinzufügen also literature review
ausbauen*

<!-- \newpage -->

# Model Describtion

## Performance Metrics

@jarmulska2020 uses sensitivity, specificity, their average as well as
the area under receiver operating curve (AUROC) as measures to assess
the effectiveness of the early warning models. Since sensitivity
corresponds to the proportion of stress episodes correctly classified
whereby specificity corresponds to the proportion of tranquil episodes
correctly classified, these metrics are dependent on the threshold,
which determines whether a period is classified as stress or tranquil
episode [@jarmulska2020]. In this paper, this threshold is specified by
maximizing the weighted sum of sensitivity and specificity. In contrast,
the AUROC is a robust measure, as all possible thresholds are taken into
account in their calculation. This measure represents the area under the
receiver operating curve, which displays the trade-off between the true
positive rate (i.e. sensitivity) and the false positive rate (i.e. 1 -
specificity). Theoretically, the AUROC can be between 0 and 1 (perfect
classifier), whereby random guessing would result in to a value of 0.5
[@fawcett2006].

## Logit Model with LASSO penalisation

@jarmulska2020 implemented two version of discrete dependent variable
models (logit regression), first a standard logit model with ordinary
least squares estimates and second a logit model with a least absolute
shrinkage and selection operator (LASSO) penalization. These models are
often used as the standard econometric approach, which is why they are
used as the benchmark in this study.

Ordinary least squares estimates often have low bias but large variance,
reducing prediction accuracy - the prediction accuracy can sometimes be
improved by shrinking some coefficients towards zero to sacrifice bias
in order to reduce variance of the predicted values and possibly improve
overall prediction accuracy [@tibshirani1996]. To do so, LASSO
penalization as proposed in @tibshirani1996 can be applied. Because of
this characteristics, only the logit LASSO model is considered in this
replication.

Following @hastie2009, the LASSO problem in the Lagrangian form is given
as follows:

```{=tex}
\begin{equation} \label{eq:lasso}
\hat{\beta}^{lasso} = \underset{\beta}{\text{argmin}} \left\{
\frac{1}{2} \sum^N_{i=1}(y_i - \beta_0 - \sum^p_{j=1}x_{ij}\beta_j)^2
+ \lambda \sum^p_{j=1}|\beta_j| \right\}
\end{equation}
```
\noindent whereby $\lambda$ corresponds to the penalization parameter.
As can be seen in Equation \eqref{eq:lasso}, the higher $\lambda$, the
higher the number of coefficients shrunk to zero. Here, $\lambda$ is
chosen by 5-fold cross-validation, maximizing the AUROC.

## Random Forest

As an alternative to the logit model, @jarmulska2020 applied the random
forest algorithm following @breiman2001 as an ensemble of multiple
classification and regression trees for binary classification. A single
tree divides the predictor space into distinct and non-overlapping
regions, whereby an observation is classified depending on the region it
falls into, i.e. at the terminal node. Each non-terminal node
corresponds to a question with a binary response, what determines the
structure of the tree. Since each terminal node assigns the same class
to all observations within this node, minimizing the classification
error at the level of the terminal nodes results in a minimization of
the tree's overall classification error [@jarmulska2020]. To measure the
precision of the fit, the Gini Index, which is used as a loss function
in classification and regression trees, can be utilised
[@jarmulska2020]:

```{=tex}
\begin{equation}
g(w) = \sum_{k \neq j}p_{wk}p_{wj} = \sum_k p_{wk}(1-p_{wk})
\end{equation}
```
\noindent whereby $p_{wj}$ corresponds to the probability distribution
of class $j$ in node $w$.

However, such decision trees might suffer from overfitting, what can be
counteracted by bootstrapping the training set and averaging all the
predictions [@james2013]. If these so called bagged trees are all
influenced by some strong predictors, the single trees might be
correlated resulting again in overfitting. To decorrelate the single
trees, the non-terminal nodes can be forced to consider only a subset of
the predictors, increasing the difference between the single trees,
through which the overfitment problem can be reduced [@james2013]. This
ensemble method corresponds to the random forest algorithm.

<!-- \newpage -->

# Data Describtion

## Dependent Variable

The binary dependent variable to be predicted follows the definition in @dobrescu2011 
takes the value of 1 in the case of a fiscal stress event and 0 otherwise.
According to the definition provided by @dobrescu2011, an economy faces a fiscal
stress event, if at least one of the following four conditions are fulfilled:
(1) the economy fails to service debt as payments come due as well as if debt
exchanges are distressed (2) ... dobrescu weiterführen



```{r stress.distr, fig.height=3, fig.cap="Distribution of Stress Periods"}
data <- list.export[["data"]]
dt <- data


dt$year <- dt$year+2
dt$crisis_next_period <- as.numeric(as.character(dt$crisis_next_period))


dt_developing <- dt[dt$developed == 0,]
dt_developed  <- dt[dt$developed == 1,]

dt_developing <- dt_developing[, names(dt_developing) %in% c("year", "crisis_next_period")]
dt_developing <- aggregate(dt_developing$crisis_next_period,
                           by = list(dt_developing$year),
                           FUN = sum)
colnames(dt_developing) <- c("year", "sum_developing")

dt_developed <- dt_developed[, names(dt_developed) %in% c("year", "crisis_next_period")]
dt_developed <- aggregate(dt_developed$crisis_next_period,
                           by = list(dt_developed$year),
                           FUN = sum)

colnames(dt_developed) <- c("year", "sum_developed")

dt <- merge(x = dt_developing, y = dt_developed,
            by = "year",
            all = T)

par(las = 1, cex = 0.6)
barplot(rbind(dt$sum_developing, dt$sum_developed), beside = T,
        names.arg = dt$year, las = 2, col = c("gray30", "gray90"))
legend("topleft",
       legend = c("developing countries", "developed countries"),
       fill = c("gray30", "gray90"))


```

## Explanatory Variables

```{r means.table}
# load relevant data
means.table <- list.export[["means.table"]]

# round numeric columns
num.cols <- sapply(means.table, mode) == "numeric"
means.table[num.cols] <- round(means.table[num.cols], 2)

# define categories
macro_globecon <- c("interest_rate_US", "dyn_GDP_US", "dyn_gdp_china", "oil_yoy",
                    "VIX", "dyn_gdp", "GDP_per_cap")
comp_domdem <- c("overvaluation", "ca_balance", "dyn_export_share", "dyn_fix_cap_form",
                 "cpi", "dyn_consum")
fin <- c("dyn_fx_rate", "diff_priv_credit_gdp")
fisc <- c("net_lending", "public_debt", "interest_on_debt")
labor <- c("diff_unempl", "dyn_prod_dol")

# add categories
means.table$category <- NA
means.table$category <- ifelse(means.table$variable %in% macro_globecon,
                               "Macroeconomic and global economy",
                               means.table$category)
means.table$category <- ifelse(means.table$variable %in% comp_domdem,
                               "Competitiveness and domestic demand",
                               means.table$category)
means.table$category <- ifelse(means.table$variable %in% fin,
                               "Financial",
                               means.table$category)
means.table$category <- ifelse(means.table$variable %in% fisc,
                               "Fiscal",
                               means.table$category)
means.table$category <- ifelse(means.table$variable %in% labor,
                               "Labor market",
                               means.table$category)

# add variable names
means.table <- merge(x = varnames, y = means.table,
                     by = "variable",
                     all = T)
means.table$variable <- NULL

# recode significance
means.table$significant <- ifelse(means.table$significant == T, "yes", "no")

# rename columns
names(means.table)[names(means.table) == "name"] <- "Variable"
names(means.table)[names(means.table) == "all_periods"] <- "All periods"
names(means.table)[names(means.table) == "tranq_periods"] <- "Tranquil periods"
names(means.table)[names(means.table) == "stress_periods"] <- "Stress periods"
names(means.table)[names(means.table) == "p_value"] <- "P-value"
names(means.table)[names(means.table) == "significant"] <- "Significance"

# make table
kbl(means.table[, -which(names(means.table) == "category")], booktabs = T,
    caption = "Means of Explanatory Variables", align = c("l", rep("r", 5))) %>%
  pack_rows(index = table(means.table$category)) %>%
  kable_styling(latex_options="scale_down")
```

<!-- \newpage -->

# Empirical Results

## Performance

```{r avg-pred-accur}
# get relevant data
dt <- list.export[["results.avg"]]

# manipulate formation
dt[!colnames(dt) %in% c("model", "auc")] <- apply(dt[!colnames(dt) %in% c("model", "auc")], 2, function(x) x*100)
dt[colnames(dt) != "model"] <- apply(dt[colnames(dt) != "model"], 2, function(x) round(x, 2))
```

```{=tex}
\begin{table}[H]
\centering
\begin{tabular}{@{\extracolsep{4pt}}lrrrr@{}}
                                             & \multicolumn{2}{c}{Logit LASSO}                                         & \multicolumn{2}{c}{Random Forest}                                       \\ \cline{2-3} \cline{4-5}
                                             & \multicolumn{1}{c}{\begin{tabular}[c]{@{}r@{}}advanced\\ dummy\end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}r@{}}GDP\\ per capita\end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}r@{}}advanced\\ dummy\end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}r@{}}GDP\\ per capita\end{tabular}} \\ \hline
\begin{tabular}[c]{@{}l@{}}\% of correctly\\ classified stress episodes\end{tabular}   & `r dt[dt$model == "logit.lasso.DUMMY",]$prop.pos` & `r dt[dt$model == "logit.lasso.GDP",]$prop.pos` & `r dt[dt$model == "rf.DUMMY",]$prop.pos` & `r dt[dt$model == "rf.GDP",]$prop.pos` \\ \hline
\begin{tabular}[c]{@{}l@{}}\% of correctly\\ classified tranquil episodes\end{tabular} & `r dt[dt$model == "logit.lasso.DUMMY",]$prop.neg` & `r dt[dt$model == "logit.lasso.GDP",]$prop.neg` & `r dt[dt$model == "rf.DUMMY",]$prop.neg` & `r dt[dt$model == "rf.GDP",]$prop.neg` \\ \hline
\begin{tabular}[c]{@{}l@{}}Average\\ \phantom{Average} \end{tabular}                                      & `r dt[dt$model == "logit.lasso.DUMMY",]$avg`      & `r dt[dt$model == "logit.lasso.GDP",]$avg`      & `r dt[dt$model == "rf.DUMMY",]$avg`      & `r dt[dt$model == "rf.GDP",]$avg`      \\ \hline
\begin{tabular}[c]{@{}l@{}}AUROC\\ \phantom{AUROC} \end{tabular}                                        & `r dt[dt$model == "logit.lasso.DUMMY",]$auc`      & `r dt[dt$model == "logit.lasso.GDP",]$auc`      & `r dt[dt$model == "rf.DUMMY",]$auc`      & `r dt[dt$model == "rf.GDP",]$auc`      \\ \hline
\end{tabular}
\caption{\label{tab:avg-pred-accur}Average prediction accuracy of early warning models for years 2009-2018}
\end{table}
```
## Interpretability of Random Forest Algorithm

### Variable Importance and Shapley Values

```{r rf.VI.SV, fig.cap="Variable Importance and Shapley Values of Predictors used", fig.height=3}
# prepare data for plot for variable importance
rf.fit.eval <- list.export[["rf.fit.eval"]]

varimp <- as.data.frame(importance(rf.fit.eval))
varimp$variable <- rownames(varimp)
varimp <- varimp[order(varimp$MeanDecreaseGini, decreasing = T), c(1,2)]
varimp$yaxis <- rev(1:nrow(varimp))

varimp <- merge(x = varimp, y = varnames,
                by = "variable",
                all = T)

varimp <- varimp[order(varimp$MeanDecreaseGini, decreasing = T), c(1:4)]
labs.varimp <- rev(varimp$name)

# prepare data for plot for shapley values
shapley.values <- list.export[["shapley.values"]]

shapley.values <- shapley.values[order(shapley.values$x, decreasing = T), c(1,2)]
shapley.values$yaxis <- rev(1:nrow(shapley.values))

shapley.values <- merge(x = shapley.values, y = varnames,
                        by.x = "Group.1", by.y = "variable",
                        all = T)

shapley.values <- shapley.values[order(shapley.values$x, decreasing = T), c(1:4)]
labs.shapley <- rev(shapley.values$name)

# draw plot
par(mar = c(5.1, 10.5, 2.1, 0.5), mfrow = c(1,2), las=1, cex = 0.75, cex.axis = 0.75, mgp = c(1.75, 0.75, 0))

# plot 1: variable importance
plot(x = varimp$MeanDecreaseGini, y = varimp$yaxis,
     main = "", xlab = "Breiman's Variable Importance", ylab = "", yaxt = "none",
     pch = 16)
abline(h = 1:20, lty = 3)
axis(side = 2, at = 1:20, labels = labs.varimp)

# plot 2: shapley values
plot(x = shapley.values$x, y = shapley.values$yaxis,
     main = "", xlab = "Shapley Values", ylab = "", yaxt = "none", pch = 16)
abline(h = 1:20, lty = 3)
axis(side = 2, at = 1:20, labels = labs.shapley)
```

### Partial dependence plots and Accumulated local effects plots

```{r rf.pdp.alep, fig.cap="Partial Dependence and Accumulated Local Effects Plots"}

# load data for partial dependence plots
partial.ca_balance  <- list.export[["partial.ca_balance"]]
partial.net_lending <- list.export[["partial.net_lending"]]

# load data for accumulated local effects plots
ale.ca_balance  <- list.export[["ale.ca_balance"]]
ale.net_lending <- list.export[["ale.net_lending"]]

# prepare plot
# x.train.eval.df <- list.export[["x.train.eval.df"]]
x.train.eval.df <- as.data.frame(list.export[["x.train.eval"]])
par(mfrow = c(2,2), mar = c(5.1, 4.1, 1, 2.1), cex = 0.65, cex.axis = 0.75, las = 1, mgp = c(2.25, 0.55, 0))

# plot upper left: pdp for ca balance
plot(x = partial.ca_balance$ca_balance, y = partial.ca_balance$yhat,
           type = "l", xlab = "Current account balance",
           ylab = "Predicted probability of stress")
rug(x.train.eval.df$ca_balance, ticksize = 0.015)

# plot upper right: ace plot for ca balance
plot(x = ale.ca_balance$results$ca_balance, y = ale.ca_balance$results$.value,
           type = "l", xlab = "Current account balance",
           ylab = "Predicted probability of stress")
rug(x.train.eval.df$ca_balance, ticksize = 0.015)

# plot lower left: pdp for net lending
plot(x = partial.net_lending$net_lending, y = partial.net_lending$yhat,
           type = "l", xlab = "Net lending",
           ylab = "Predicted probability of stress")
rug(x.train.eval.df$net_lending, ticksize = 0.015)

# plot lower right: ace plot net lending 
plot(x = ale.net_lending$results$net_lending, y = ale.net_lending$results$.value,
           type = "l", xlab = "Net lending",
           ylab = "Predicted probability of stress")
rug(x.train.eval.df$net_lending, ticksize = 0.015)
```

<!-- \newpage -->

# Conclusion

<!-- References --------------------------------------------------------------->

\newpage

# References

The code and data used for this project can be found in the
corresponding GitHub-repository:
\mbox{\texttt{\url{https://github.com/bt-koch/ML-in-Economics}}}.

\vspace{1cm}

\bibliography{tex/bibliography.bib}
